{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvbkHQQkSzdi"
   },
   "source": [
    "# CSCC11 - Introduction to Machine Learning, Fall 2022, Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "pK-Wu4hfz97-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "e5f5zgrD0DHJ"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Read the csv file into a DataFrame - df\n",
    "\"\"\"\n",
    "df = pd.read_csv('Admission_Predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "UlYEmMORp1nv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>396</td>\n",
       "      <td>324</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>397</td>\n",
       "      <td>325</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>330</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>399</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>400</td>\n",
       "      <td>333</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "395         396        324          110                  3  3.5   3.5  9.04   \n",
       "396         397        325          107                  3  3.0   3.5  9.11   \n",
       "397         398        330          116                  4  5.0   4.5  9.45   \n",
       "398         399        312          103                  3  3.5   4.0  8.78   \n",
       "399         400        333          117                  4  5.0   4.0  9.66   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "395         1              0.82  \n",
       "396         1              0.84  \n",
       "397         1              0.91  \n",
       "398         0              0.67  \n",
       "399         1              0.95  \n",
       "\n",
       "[400 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print the DataFrame\n",
    "\"\"\"\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qG0T29UBp1nw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "Index(['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
      "       'LOR ', 'CGPA', 'Research', 'Chance of Admit '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Print the length of the DataFrame.\n",
    "Print the column names of the DataFrame.\n",
    "\"\"\"\n",
    "print(len(df))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "eI7SRu_kp1nx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 7)\n",
      "(400, 1)\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Define an “X” array that would hold our independent features for regression purposes.  \n",
    "Define a \"Y\" array that would hold our target variable.\n",
    "\n",
    "Print the shape of both the arrays.\n",
    "\"\"\"\n",
    "X = df[['GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
    "       'LOR ', 'CGPA', 'Research']].to_numpy(copy = True)\n",
    "print(np.shape(X))\n",
    "\n",
    "Y = df[['Chance of Admit ']].to_numpy(copy = True)\n",
    "print(np.shape(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5xnt6Wfp1ny"
   },
   "source": [
    "## Split the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "JPZ5RlYQp1ny"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "\"\"\"\n",
    "Split the dataset into train dataset and test dataset.\n",
    "Set the random state to any number in order to maintain consistency while generating random numbers over several runs.\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eY7EqYsZp1nz"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "hu8lbAnVp1nz"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def find_optimal_parameters(x, y):\n",
    "    \"\"\" Compute closed form solution for linear regression!\n",
    "    Optimal weight w* in linear regression is given by w* = (X^T X)^(-1) X^T Y\n",
    "    \n",
    "    Args:\n",
    "    - x (ndarray (Shape: (N, D))): A NxD matrix corresponding to the inputs.\n",
    "    - y (ndarray (Shape: (N, 1))): A N-column vector corresponding to the outputs given the inputs.\n",
    "    \n",
    "    Output:\n",
    "    - w (ndarray (Shape: (D, 1))): A D-column vector corresponding to the bias and weights of the linear model.\n",
    "    \"\"\"\n",
    "    # Pad 1's for the bias term, Why?\n",
    "    # 1 at the front: x = np.hstack((x, np.ones((x.shape[0], 1))))\n",
    "    x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "\n",
    "    # Note that we could use pseudoinverse here instead: np.linalg.pinv\n",
    "    # @ is alias for matmul\n",
    "    p = np.linalg.pinv(x)\n",
    "    w = np.matmul(p,y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hef0J8wPp1nz"
   },
   "source": [
    "### Train linear regression model using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "b2tMQBXYp1n0"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def get_pred_Y(trained_w, X_pred):\n",
    "    \"\"\" Return predicted Y\n",
    "    Args:\n",
    "    - trained_w (ndarray (Shape: (D+1, 1))): A (D+1)x1 column vector containing linear regression weights.\n",
    "    - X_pred (ndarray (Shape: (N, D))): A NxD matrix corresponding to the prediction inputs.\n",
    "    \n",
    "    Output:\n",
    "    - pred_Y (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \"\"\"\n",
    "    pad_Y     = np.hstack((np.ones((X_pred.shape[0],1)), X_pred))\n",
    "    pred_Y    = pad_Y @ trained_w\n",
    "    return pred_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "NvJEIbPFp1n0"
   },
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "def get_mae(Y_truth, Y_pred):\n",
    "    \"\"\" Return Mean absolute error\n",
    "    Args:\n",
    "    - Y_truth (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the actual outputs.\n",
    "    - Y_pred (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \n",
    "    Output:\n",
    "    - MSE (ndarray (Shape: (1,))).\n",
    "    \"\"\"\n",
    "    'check if both inputs are of the same shape'\n",
    "    if np.shape(Y_truth) == np.shape(Y_pred):\n",
    "        Y_mean = Y_truth - Y_pred\n",
    "        mae    = np.mean(np.abs(Y_mean))\n",
    "        return mae\n",
    "    return -1\n",
    "\n",
    "def get_mse(Y_truth, Y_pred):\n",
    "    \"\"\" Return Mean squared error\n",
    "    Args:\n",
    "    - Y_truth (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the actual outputs.\n",
    "    - Y_pred (ndarray (Shape: (N, 1))): A Nx1 column vector corresponding to the predicted outputs.\n",
    "    \n",
    "    Output:\n",
    "    - MSE (ndarray (Shape: (1,))).\n",
    "    \"\"\"\n",
    "    'check if both inputs are of the same shape'\n",
    "    if np.shape(Y_truth) == np.shape(Y_pred):\n",
    "        Y_mean = Y_truth - Y_pred\n",
    "        mse    = np.mean(np.square(Y_mean))\n",
    "        return mse\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihQlEbDzp1n1"
   },
   "source": [
    "### Get predictions on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ycC9grI0rKkn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.33382323]\n",
      " [ 0.00194302]\n",
      " [ 0.00305205]\n",
      " [ 0.01160164]\n",
      " [-0.01123125]\n",
      " [ 0.02232715]\n",
      " [ 0.1196734 ]\n",
      " [ 0.01890553]]\n"
     ]
    }
   ],
   "source": [
    "w_optimal = find_optimal_parameters(X_train, Y_train)\n",
    "print(w_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "jntfL_s7p1n1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error (MSE):  0.00396475638879563\n",
      "train error (MAE):  0.04501915140243021\n"
     ]
    }
   ],
   "source": [
    "pred_Y    = get_pred_Y(w_optimal, X_train)\n",
    "print('train error (MSE): ', get_mse(Y_train, pred_Y))\n",
    "print('train error (MAE): ', get_mae(Y_train, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrQ5lClCp1n1"
   },
   "source": [
    "### Get predictions and performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Od4gUr8jp1n1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error (MSE)::  0.004167237997155191\n",
      "test error (MAE):  0.046087751020785696\n"
     ]
    }
   ],
   "source": [
    "pred_Y    = get_pred_Y(w_optimal, X_test)\n",
    "print('test error (MSE):: ', get_mse(Y_test, pred_Y))\n",
    "print('test error (MAE): ', get_mae(Y_test, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsVtfDC12Rh_"
   },
   "source": [
    "# Silouette Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "MBUC-6gR2Vh7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters =  2 : The average silhouette_score is :  0.5233485180906523\n",
      "For n_clusters =  3 : The average silhouette_score is :  0.45731266107412905\n",
      "For n_clusters =  4 : The average silhouette_score is :  0.45690921050567296\n",
      "For n_clusters =  5 : The average silhouette_score is :  0.39334039890325867\n",
      "For n_clusters =  6 : The average silhouette_score is :  0.3531532855174821\n",
      "For n_clusters =  7 : The average silhouette_score is :  0.3403140674851437\n",
      "For n_clusters =  8 : The average silhouette_score is :  0.31526382401888964\n",
      "For n_clusters =  9 : The average silhouette_score is :  0.3171131560867962\n",
      "For n_clusters =  10 : The average silhouette_score is :  0.31190098933430455\n"
     ]
    }
   ],
   "source": [
    "#TO-DO\n",
    "n_silhouette = []\n",
    "\n",
    "kmeans_kwargs= {\n",
    "    \"init\":\"k-means++\",\n",
    "    \"n_init\":30,\n",
    "    \"max_iter\":250,\n",
    "    \"random_state\":2\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Perform the following steps:\n",
    "\n",
    "1. Loop over the various possible K values you wish to test\n",
    "2. Initialize a K means object.\n",
    "3. Fit the training data on the K means object.\n",
    "4. Use the silhouette score method available from the sklearn metrics.\n",
    "5. Append the score to the silhouetter_coefficients list.\n",
    "6. Display the the silhouette coefficient associated with each value of K.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for n in range(2,11):\n",
    "    clusters = KMeans(n_clusters = n, init = kmeans_kwargs['init'],\n",
    "        n_init = kmeans_kwargs['n_init'], max_iter = kmeans_kwargs['max_iter'],\n",
    "        random_state = kmeans_kwargs[\"random_state\"])\n",
    "    labels = clusters.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, labels)\n",
    "    print(\"For n_clusters = \", n, \": The average silhouette_score is : \",\n",
    "        silhouette_avg)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0H6Djcju85JN"
   },
   "source": [
    "# K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "6BvShiJG88NZ"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4109611177.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [84], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    training_df_clustered =\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(\n",
    "    init=\"k-means++\",\n",
    "    n_clusters = 2, #Input the value you configured using the Silhouette coefficient analysis.\n",
    "    n_init=30,\n",
    "    max_iter=250,\n",
    "    random_state=2\n",
    ")\n",
    "\n",
    "#TO-DO\n",
    "# Fit to the training data\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "#TO-DO\n",
    "# Add the features and the training data you used to the variable below.\n",
    "training_df_clustered = pd.DataFrame(X_train.copy(), columns = ['GRE Score', 'TOEFL Score',\n",
    "    'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research'])\n",
    "\n",
    "#TO-DO\n",
    "# Predict clusters for the training data\n",
    "train_cluster = kmeans.predict(X_train)\n",
    "\n",
    "#TO-DO\n",
    "# Add the target and predicted clusters to the training DataFrame\n",
    "training_df_clustered['cluster'] = train_cluster\n",
    "\n",
    "#TO-DO\n",
    "# Set the number of clusters based on the silhouette coefficient analysis\n",
    "number_cluster = 2\n",
    "\n",
    "X_train_clusters_df = []\n",
    "for i in range(number_cluster):\n",
    "    X_train_clusters_df.append(training_df_clustered[training_df_clustered['cluster']==i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVbD_sYQ88qB"
   },
   "source": [
    "# Building Linear Regression for our clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMwMKQEpLm2F"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\"\n",
    "The number of clusters would be defined by the outcome of the silhouetter coefficient \n",
    "Set up the model of Linear Regression by exploring the different parameters: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "train_clusters_df is a dataframe that contains both the true cluster values and the predicted cluster values. Feel free to change the variable name to something else if you have been following a different naming convention.\n",
    "\"\"\"\n",
    "\n",
    "#TO-DO\n",
    "# Set the number of clusters based on the silhouette coefficient analysis\n",
    "number_cluster = 2\n",
    "obj_cluster = []\n",
    "\n",
    "#TO-DO\n",
    "# Initialize a Linear Regression object.\n",
    "\n",
    "for i in range(number_cluster):\n",
    "    #Get the specific X_train values according to their predicted clusters.\n",
    "    X_clustered_data = \n",
    "    #Get the specific Y_train values according to their predicted clusters.\n",
    "    Y_clustered_data = \n",
    "    obj_cluster.append(__________.fit(X_clustered_data, Y_clustered_data)) #Replace the underlines with the variable name you used to create the Linear Regression object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOF-lX3dL97-"
   },
   "outputs": [],
   "source": [
    "def predict_value(x_test, kmeans, cluster_linear):\n",
    "  \"\"\"\n",
    "  Input: \n",
    "  x_test is the test value that you wish to predict on.\n",
    "  kmeans is the kmeans object that you have finalized to predict on the test dataset.\n",
    "  cluster_linear is the list of fitted models on different clusters.\n",
    "\n",
    "  Return:\n",
    "  linear_pred - linear_pred will be type list with prediction values\n",
    "  clusters - clusters_pred will be the prediction of clusters using k means.\n",
    "\n",
    "  Follow these steps:\n",
    "  1. Predict clusters using K means object on the test data.\n",
    "  2. Predict regression values using Linear Regression list.\n",
    "  3. return both the predictions.\n",
    "\n",
    "  \"\"\"\n",
    "  linear_pred = []\n",
    "  clusters = []\n",
    "  return linear_pred, clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-KOf0ncBvkN"
   },
   "source": [
    "# Final Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAYyCLx8Bcwb"
   },
   "outputs": [],
   "source": [
    "#Apply the clustering-based linear regression to the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hTtpG7j91JL"
   },
   "outputs": [],
   "source": [
    "print('test error (MSE):: ', get_mse(Y_test, np.array(Y_svr_k_means_pred).reshape(125,1)))\n",
    "print('test error (MAE): ', get_mae(Y_test, np.array(Y_svr_k_means_pred).reshape(125,1)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
